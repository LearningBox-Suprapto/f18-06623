{"cells":[{"cell_type":"markdown","metadata":{},"source":["\n# Review\n\n"]},{"cell_type":"markdown","metadata":{},"source":["\n## Initial guess methods\n\n"]},{"cell_type":"markdown","metadata":{},"source":["It is hard to find initial guesses. If you can plot the functions you should. This works for two or three variables. With two variables you can plot the functions. With three variables,  you can use contour plots (see [http://kitchingroup.cheme.cmu.edu/blog/2013/02/05/Constrained-minimization-to-find-equilibrium-compositions/>](http://kitchingroup.cheme.cmu.edu/blog/2013/02/05/Constrained-minimization-to-find-equilibrium-compositions/>)for an example).\n\nIf you can't plot them, you have to do some analysis, use prior knowledge, or be clever. This kind of analysis is the subject of dedicated courses in optimization.\n\nSometimes you can solve a simpler problem first [http://kitchingroup.cheme.cmu.edu/blog/2013/02/22/Method-of-continuity-for-nonlinear-equation-solving/](http://kitchingroup.cheme.cmu.edu/blog/2013/02/22/Method-of-continuity-for-nonlinear-equation-solving/). Another approach is to fix some variables, and then iteratively solve the problem.\n\nIn the worst case scenario, you can try a brute force grid search, or random search.\n\n"]},{"cell_type":"markdown","metadata":{},"source":["\n## fsolve questions\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Why do we write the , in the args below?\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"array([ 4.])"}],"source":["def objective(x, k):\n    return x - k**2\n\nx0 = 2\nfsolve(objective, x0, args=(2,))"]},{"cell_type":"markdown","metadata":{},"source":["In questions like this, we start with the documentation.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["from scipy.optimize import fsolve\n?fsolve"]},{"cell_type":"markdown","metadata":{},"source":["Now, let's look at some syntax:\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"float"}],"source":["k = 0.2\ntype(k)"]},{"cell_type":"markdown","metadata":{},"source":["Parentheses by themselves are just for grouping. They do not change the type.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"float"}],"source":["args = (k)\ntype(args)"]},{"cell_type":"markdown","metadata":{},"source":["When we want a tuple with a single element in it, we add a , to make it a tuple.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"tuple"}],"source":["args = (k,)\ntype(args)"]},{"cell_type":"markdown","metadata":{},"source":["It turns out fsolve is flexible in this case, and we can get away with writing:\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"array([ 4.])"}],"source":["fsolve(objective, 1, args=2)"]},{"cell_type":"markdown","metadata":{},"source":["\n## What is the difference between the standard error of the mean and standard deviation?\n\n"]},{"cell_type":"markdown","metadata":{},"source":["The standard deviation represents the spread, or deviation, in a dataset from its mean. The standard deviation is a feature of a data set.\n\nThe standard error of the mean is how far is the estimated mean likely to be from the true population mean. The standard error arises because we *estimate* the average from a small number of data points, so we never know it exactly. The standard error tends towards zero, however, as the number of data points gets large. That does not mean there is no noise in the data, just that we have no uncertainty about the average.\n\n$SE = \\frac{sd}{\\sqrt{n}}$\n\nIn lecture 11, we looked at the confidence intervals of an average where we used: `std_x / np.sqrt(n)`. Here we have to compute the standard error from the standard deviations.\n\nLater, in the regression, we used:\n\n`p + sigma * tval`\n\nHere, `sigma` came from the square root of the covariance matrix diagonal, which is defined as the standard error, so we do not divide by the square root of N in this case.\n\n"]}],"metadata":{"org":null,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}
